---
title: "Identifying Predictors of Depression of Adults Aged 40 to 59"
author: "Nic Kane"
date: "2025-05-19"
output: 
  pdf_document: 
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1. State the problem and find the data set.

```{r}
heart <- read.csv("https://raw.githubusercontent.com/PlasticEnergyMan/MATH-449-Final-Project/refs/heads/main/heart_failure_clinical_records_dataset.csv", 
              header=TRUE)
head(heart)
```

The problem explored is the survival of heart failure. The data set includes 12 predictors and our focus is finding an intersection between the simplest and most accurate model.

# 2. Fit a logistic model with all predictors.

```{r}
fit1 <- glm(DEATH_EVENT ~ age + anaemia + creatinine_phosphokinase + diabetes +
              ejection_fraction + high_blood_pressure + platelets + serum_creatinine +
              serum_sodium + sex + smoking + time, family = binomial, data = heart)

summary(fit1)
```

Full model lists age, ejection fraction, serum creatinine, and time as significant predictors. We remove other predictors.

# 3. Select the best subset of variables. Perform a diagnostic on the best model. Perform all possible inferences you can think about. Perform goodness of fit tests. Find confidence intervals for multiplicative effects.

```{r}
library(MASS)
step(fit1)
stepAIC(fit1, direction="backward")

fit2 <- glm(DEATH_EVENT ~ age + serum_creatinine + ejection_fraction + time,
            family = binomial, data = heart)

summary(fit2)

drop1(fit2, test="LRT")

fit0 <- glm(DEATH_EVENT ~ 1, family = binomial, data = heart)

anova(fit2, fit1, test = "Chisq")

anova(fit0, fit2, test = "Chisq")

res=rstandard(fit2,type="pearson")

boxplot(res, ylim=c(-5,5))

conf=confint(fit2)
```

The best model includes only the four predictors selected previously. When compared to the null model, it performs just as well, and when compared to the saturated it preforms better. We can analyze the residuals and see that our model is good, but not perfect as most lie between -3 and 3. Confidence intervals are also found above, and a more in depth table is found in the report. Serum creatinine and age have a positive effect, while time and ejection fraction have a negative effect.

# 4. Use the new model to make predictions

```{r}
library(caret)
heart$prob <- predict(fit2, type="response")
Predicted1 <- ifelse(heart$prob > 0.5, 1, 0)
expected_value1 <- factor(heart$DEATH_EVENT)
predicted_value1 <- factor(Predicted1)
conmat1 <- confusionMatrix(data=predicted_value1, reference = expected_value1)
conmat1
```

When making predictions with a cutoff point of 0.5, we find that we get a high sensitivity of 0.9015, but a low specificity of 0.6875. This gives an overall accuracy of 0.8328, which is good, but not great.

# 5. Use different pi_0 as cutoff points

```{r}
Predicted2 <- ifelse(heart$prob > 0.25, 1, 0)
expected_value2 <- factor(heart$DEATH_EVENT)
predicted_value2 <- factor(Predicted2)
conmat2 <- confusionMatrix(data=predicted_value2, reference = expected_value2)
conmat2

Predicted3 <- ifelse(heart$prob > 0.3, 1, 0)
expected_value3 <- factor(heart$DEATH_EVENT)
predicted_value3 <- factor(Predicted3)
conmat3 <- confusionMatrix(data=predicted_value3, reference = expected_value3)
conmat3

Predicted4 <- ifelse(heart$prob > 0.4, 1, 0)
expected_value4 <- factor(heart$DEATH_EVENT)
predicted_value4 <- factor(Predicted4)
conmat4 <- confusionMatrix(data=predicted_value4, reference = expected_value4)
conmat4

Predicted5 <- ifelse(heart$prob > 0.6, 1, 0)
expected_value5 <- factor(heart$DEATH_EVENT)
predicted_value5 <- factor(Predicted5)
conmat5 <- confusionMatrix(data=predicted_value5, reference = expected_value5)
conmat5

Predicted6 <- ifelse(heart$prob > 0.75, 1, 0)
expected_value6 <- factor(heart$DEATH_EVENT)
predicted_value6 <- factor(Predicted6)
conmat6 <- confusionMatrix(data=predicted_value6, reference = expected_value6)
conmat6

Predicted7 <- ifelse(heart$prob > 0.85, 1, 0)
expected_value7 <- factor(heart$DEATH_EVENT)
predicted_value7 <- factor(Predicted7)
conmat7 <- confusionMatrix(data=predicted_value7, reference = expected_value7)
conmat7
```

# 6. Perform visualization of data and models.

```{r}
library(ggeffects)

ggpredict(fit2, terms = c("age")) |> plot()

ggpredict(fit2, terms = "serum_creatinine[all]") |> plot()

ggpredict(fit2, terms = "ejection_fraction[all]") |> plot()

ggpredict(fit2, terms = "time[all]") |> plot()
```

# 7. Plot the ROC curve, find AUC, and the best cutoff point for classification.

```{r}
library(Epi)
ROC(form = DEATH_EVENT ~ age + serum_creatinine + ejection_fraction + time, plot="ROC", data = heart)

Predicted8 <- ifelse(heart$prob > 0.312, 1, 0)
expected_value8 <- factor(heart$DEATH_EVENT)
predicted_value8 <- factor(Predicted8)
conmat8 <- confusionMatrix(data=predicted_value8, reference = expected_value8)
conmat8
```

The AUC is 0.891 with a best cutoff point of $\pi_0=0.312$. However, when compared to our various confusion tables, we find that a much higer $pi_0$ performs better. This discrepancy is most likely due to data imbalance (1/3 is death, 2/3 is survive).

# 8. Perform LOOCV and and k fold cross validation

```{r}
library(boot)
#LOOCV
out0=cv.glm(data = heart, glmfit = fit2)

#10-fold
cost<-function(r,pi=0) {
  mean(abs(r-pi)>0.312)}
out1=cv.glm(data = heart, glmfit = fit2, cost, K=10)

out0$delta #LOOCV
out1$delta #10-fold
```

LOOCV is much better whereas 10-fold is worse. This again is most likely due to slightly unbalanced data.

# 9. Try the probit link and identity links to model data.

```{r}
fit4 <- glm(DEATH_EVENT ~ age + serum_creatinine + ejection_fraction + time, 
            family=binomial(link="probit"), data = heart)

summary(fit4)

heart$prob2 <- predict(fit4, type="response")
Predicted9 <- ifelse(heart$prob2 > 0.312, 1, 0)
expected_value9 <- factor(heart$DEATH_EVENT)
predicted_value9 <- factor(Predicted9)
conmat9 <- confusionMatrix(data=predicted_value9, reference = expected_value9)
conmat9
```

Identity model was not possible to run.

# 10. Which model works better for the data?

Logit performs marginally better, both are at about the same level

# 11. I do not have grouped data

# 12. Write a report.

This is in the attached document.
